- RAG enabled LLM using HuggingFace model - HuggingFaceH4/zephyr-7b-beta
- Upload multiple PDFs and chat with an LLM that answers based on the PDF content provided.
- FAISS Vectorstore database for content storage and semantic search used as context retrieval system for the LLM to use.
- Enables Conversation Memory for the LLM to use and display in the chat window.

- Check out the app hosted at HuggingFace Spaces in <a href traget = "https://huggingface.co/Dekode"> Dekode/DocLLM </a>

- check out my <a href traget = "https://huggingface.co/Dekode"> HuggingFace profile </a>
